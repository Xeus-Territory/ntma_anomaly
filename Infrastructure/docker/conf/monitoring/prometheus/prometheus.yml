# my global config
global:
  scrape_interval: 10s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - "alertmanager:9093"

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
    - "alert.rules.yml"
    - "metrics.rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
- job_name: 'cadvisor'
  file_sd_configs:
  - files:
      - "./target/cadvisor.json"
- job_name: 'node-exporter'
  file_sd_configs:
  - files:
      - "./target/node-exporter.json"
- job_name: 'nginx-exporter'
  file_sd_configs:
  - files:
      - "./target/nginx-exporter.json"
- job_name: 'nginxlog-exporter'
  file_sd_configs:
  - files:
      - "./target/nginxlog-exporter.json"

remote_write:
      - url: "http://prometheus-kafka-adapter:8080/receive"
        write_relabel_configs:
        - source_labels: [__name__]
          regex: "service_avg_cpu_usage_percentage|service_avg_memory_usage_percentage|service_avg_network_receive_bytes|service_avg_network_transmit_bytes|nginx_avg_respone_time|nginx_requests_per_second|nginx_received_http_traffic|nginx_sent_http_traffic"
          action: keep
